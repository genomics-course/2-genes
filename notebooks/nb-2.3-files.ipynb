{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 2.3: Files I/O\n",
    "\n",
    "This notebook will correspond with chapter 7 in the official Python tutorial https://docs.python.org/3/tutorial/.  \n",
    "\n",
    "\n",
    "### Learning objectives: \n",
    "\n",
    "By the end of this exercise you should:\n",
    "\n",
    "1. Understand how to import libraries.\n",
    "2. Read and write data to files. \n",
    "3. Be able to load fastq genomic data from a file to a Python object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing a package\n",
    "Python is very *atomic* language, meaning that many packages in the standard library are packaged into individual libraries that need to be loaded in order to access their utilities. This makes Python very light weight since the base language does not need to load all of these extra utilities unless we ask it to. To load a package that is installed on our system we can call the `import` function like below. Here we are also using a package that is not part of the standard library but was installed separately, called requests, which is used to download data from the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data files for this notebook\n",
    "Run the bash script below to create a new folder and download two files that we will use in this notebook into that folder. This code should look familiar, we used very similar bash commands in the notebooks from session 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p datafiles/\n",
    "wget http://eaton-lab.org/data/40578.fastq.gz -q -O datafiles/40578.fastq.gz\n",
    "wget http://eaton-lab.org/data/iris-data-dirty.csv -q -O datafiles/iris-data-dirty.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform the same task using Python. Here we will name the directory for the files \"datafiles2\" to differentiate it. In this case the Python version of the code looks quite a bit more complicated than the bash script. This isn't always the case, indeed Python code is often much simpler to read. By the end of this notebook you should be able to understand the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new directory\n",
    "os.makedirs(\"datafiles2\", exist_ok=True)\n",
    "\n",
    "# download files to that directory\n",
    "url1 = \"http://eaton-lab.org/data/40578.fastq.gz\"\n",
    "with open(\"./datafiles2/40578.fastq.gz\", 'wb') as ffile:\n",
    "    ffile.write(requests.get(url1).content)\n",
    "\n",
    "url2 = \"http://eaton-lab.org/data/iris-data-dirty.csv\"\n",
    "with open(\"./datafiles2/iris-data-dirty.csv\", 'wb') as ffile:\n",
    "    ffile.write(requests.get(url2).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List directories\n",
    "Another common tool that we used in the bash terminal is the `ls` command to look at the files in a given location in the filesystem. Below is the `ls` command as well as a Python equivalent. The `os.listdir()` function in Python returns the contents as a `list`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls datafiles/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"datafiles2/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using packages\n",
    "The `os` package has many functions but we will be using just a small part of it today, primarily the `path` submodule. Just like everything else in Python packages are also objects, and so we can access all of the functions in this package using tab completion. Put your cursor after the period in the cell below and press `<tab>` to see available options in `os`. There are many!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use tab-completion after the '.' to see available options in os\n",
    "os."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filepath operations with the `os` package\n",
    "A type of string that is often difficult to format properly when writing code is a filepath. If the string representation of a filepath is incorrect by even a single typo then the path will not be found. This becomes extra tricky when a program needs to access filepaths on different types of computers, since filepaths look different on a Mac and PC, for example. Here understanding the filesystem hierarchy that we learned in lesson 1 becomes important. Fortunately the `os.path` package makes this easy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `os.path`\n",
    "The `os.path` submodule is used to format filepaths. We can expand shortened path names, we can join together multiple paths, we can search for special directories like $HOME, or current directory. Essentially, the package is making calls similar to those we learned from bash scripting last week, such as `pwd` to show your current directory, or `~` as a shorthand for your home directory. Here we can access those filepaths as string variables and work with them very easily. \n",
    "\n",
    "NB: The goal here is not for you to master the `os` package, but to understand that many such packages exist in the Python standard library and that you can use tab-completion, google search, and other sources to find them and how to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return my $HOME directory\n",
    "os.path.expanduser(\"~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert relative path to a full path\n",
    "os.path.abspath('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Action:</b> Write a relative path to the iris-data-dirty.csv file that we downloaded earlier and expand it to a full path using the `os.path.abspath()` function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations on filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign my current dir to a variable\n",
    "curdir = os.path.abspath('.')\n",
    "curdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the lowest level directory in curdir\n",
    "os.path.basename(curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the directory structure above curdir\n",
    "os.path.dirname(curdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining filepaths\n",
    "Because it can be hard to keep track of the \"/\" characters between directories and filepaths it is useful to use the `.join` function of the `os.path` module to join together path names. Here we will create string variable with a new pathname for a file that doesn't yet exist in our current directory. You can see in the three examples below that it doesn't matter when we include a \"/\" after a directory name or not, the `join` function figures it out for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how os.path.join handles '/' characters in path names\n",
    "print(os.path.join(\"/home/user/fakeuser\", \"folder1/\", \"folder2\", \"newfile.txt\"))\n",
    "print(os.path.join(\"/home/user/fakeuser\", \"folder1\", \"folder2\", \"newfile.txt\"))\n",
    "print(os.path.join(\"/home/user/fakeuser/\", \"folder1/\", \"folder2/\", \"newfile.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the full path name to a newfile in our current directory\n",
    "newfile = os.path.join(curdir, \"newfile.txt\")\n",
    "newfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing files\n",
    "\n",
    "The function `open` can be used to create views of files. The format for this is `open(filename, mode)` where mode is the thing you plan to do with this file. The main arguments for this are `w` for 'write', `r` for 'read', or `a` for append. Below we will use `w` to write, which we can use to create a new file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an open file object\n",
    "ofile = open(\"./datafiles/helloworld.txt\", 'w')\n",
    "\n",
    "# see the file object\n",
    "ofile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File objects\n",
    "As with other objects, `ofile` has attributes and functions that we can access and see by using tab-completion. Move your cursor to the end of the object below after the period and use tab to see some of the options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use tab to see options associated with open file objects\n",
    "ofile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `.write()` function to write a string to the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a string to the file. \n",
    "# It returns the number of characters written, which we can ignore for now.\n",
    "ofile.write(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when we are done writing to the file use .close()\n",
    "ofile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading files\n",
    "To read the data from a file we use a similar format as to write, but with the mode flag `r`. When we show the representation of the file object below you can see that this also returns an open file object, but this time in read mode. We can now access a different set of functions from this object to retrieve data from the file. We will use the `.read()` function to read and return all contents from the file as a string object and store it as the variable `idata`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifile = open(\"./datafiles/iris-data-dirty.csv\", 'r')\n",
    "ifile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read returns all of the contents as a string\n",
    "idata = ifile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show the first 50 characters\n",
    "idata[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## close the file handle\n",
    "ifile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gzip compressed files\n",
    "Gzip compression, as well as many other forms of compression are easily handled in Python using the standard library. The `gzip` module has an `open()` function that acts just like the regular `open` to create a file object. Let's try it out on the compressed fastq file we just downloaded. \n",
    "\n",
    "Let's also practice using `os.path` to find the full filepath of the `40578.fastq.gz` file. \n",
    "\n",
    "Then, as in the last example we simply use `.read()` to read the full contents and store it in a variable. Because the data in this file is stored as a bytestring we need to also add `.decode()` to convert it to a `utf-8` string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get full path to the file in our current directory\n",
    "gzfile = os.path.abspath(\"./datafiles/40578.fastq.gz\")\n",
    "gzfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read compressed byte data from this file\n",
    "ffile = gzip.open(gzfile, 'rb')\n",
    "fdata = ffile.read().decode()\n",
    "ffile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## show some data from the file\n",
    "print(fdata[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data with the `read()` function\n",
    "The `read()` function is nice for reading in a large chunk of text, but it then requires us to parse that text using string processing, like we learned in our earlier notebook. Let's use string processing to split the contents of the file into a list. Perhaps instead of separating contents on every line, as we did for this file when we analyzed it from a bash terminal, we instead would like to chunk it up so that it is split into elements that cover four lines. We can do this by using our own \"split\" separator. From looking at the text above we can see that each four line element is separated by a `\"\\n@\"` character, so we'll use that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split the fdata string on each occurrence of \"\\n@\"\n",
    "freads = fdata.split(\"\\n@\")\n",
    "\n",
    "## print the first element in the list\n",
    "print(\"The first read: \\n{}\".format(freads[0]))\n",
    "\n",
    "## print the last element in the list\n",
    "print(\"\\nThe last read: \\n{}\".format(freads[-1]))\n",
    "\n",
    "## print the number of reads in the file\n",
    "print(\"\\nN reads in the file = {}\".format(len(freads)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The fastq file format\n",
    "Read details of the [fastq file format here](https://en.wikipedia.org/wiki/FASTQ_format). This is a file format for next-generation sequence data that we will use frequently throughout this course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Phred quality scores\n",
    "The fastq sequence format stores sequence reads "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using context to automatically open & close files\n",
    "\n",
    "In Python there is a special keyword called `with` that can be used to wrap statements into a context dependency. That means that everything which takes place inside of the with statement will know about what happend in the with statement. This is often used to open a file object. File objects have a context dependency so that when they are opened with `with` they will automatically close themselves when the statement is ended. See an example below. This is a much more compact way of opening and closing files than what we were using before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## infile will automatically close when finished.\n",
    "with open(\"./datafiles/iris-data-dirty.csv\", 'r') as infile:\n",
    "    data = infile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data from the web in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard format for using the `requests` library is to make a GET request to a url, which is a request to read the data from that page. This will return a `response` object which we can then access for information. The `response` object will contain an error message if the url is invalid, or blocked, and it will contain the HTML text of the webpage if it is successful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store urls as strings\n",
    "url1 = \"http://eaton-lab.org/data/40578.fastq.gz\"\n",
    "url2 = \"http://eaton-lab.org/data/iris-data-dirty.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new variable 'response' here is a Python object just like the other object types we've learned about. We can access functions of this object using tab completion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the response object (200 means successful GET)\n",
    "response = requests.get(url2)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first 50 characters of data\n",
    "response.text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the string of text on each newline character\n",
    "lines = response.text.split(\"\\n\")[:10]\n",
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often useful to split a string into separate elements as a list, and then operate on those list elements. When finished, we then wish to join the list elements back together into a string object. This can be done using the `.join()` function, which is a function of string objects. The object calling join is the string that you want to be placed in between each element of the list being joined. Some examples below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join together lines with no separator\n",
    "\"\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join on newline characters\n",
    "\"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember newlines are only rendered when you print\n",
    "print(\"\\n\".join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join on an arbitrary phrase\n",
    "\"Helloworld\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges\n",
    "Your challenge is to perform similar tasks to those we did in the first bash assignment, but using Python. We'll focus on filtering and counting the Iris data set. This will use the skills you learned for operating on strings and lists, as well as reading and writing files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Action:</b> \n",
    "    This challenge builds on the last challenge from the last notebook. You can reuse your function from the last notebook to generate random sequence data. Write code below to combine a fasta header (e.g., \"> sequence name\") and random sequence data to create valid fasta data. Then write the data to a file and save it as \"datafiles/sequence.fasta\". \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Action:</b> \n",
    "    You have now learned about two sequence file formats, fasta and fastq. If you do not remember the details of fasta then use google or look back at your notebooks from session 1. Fastq contains more information than fasta since it also stores quality information for each base. Your challenge here is to write a function to convert one format to the other. All of the code you need is composed in snippets in examples above. Feel free to use google or the chatroom to seek further help if needed. Your answer must: (1) Write a function; (2) The function must read the 'datafiles/40578.fastq.gz' file from disk; (3) It must convert the data to fasta format; and (4) It must write the result to a file \"datafiles/40578.fasta\".     \n",
    "    \n",
    "Be sure you look at your fasta file after you write it to check that it looks how you expect. If not, modify your code and try again. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Question:</b> \n",
    "   Describe each step of your function above verbally, in other words, explain how and why it works. Describe any parts that gave you trouble and how you found a solution. Enter your answer below using Markdown. \n",
    "   </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Action:</b> \n",
    "    Save your notebook and download as HTML to upload to courseworks.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
