{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 2.3: Files I/O\n",
    "\n",
    "This notebook will correspond with chapter 7 in the official Python tutorial https://docs.python.org/3/tutorial/.  \n",
    "\n",
    "\n",
    "### Learning objectives: \n",
    "\n",
    "By the end of this exercise you should:\n",
    "\n",
    "1. Understand how to import libraries.\n",
    "2. Read and write data to files. \n",
    "3. Be able to load fastq genomic data from a file to a Python object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing a package\n",
    "Python is very *atomic* language, meaning that many packages in the standard library are packaged into individual libraries that need to be loaded in order to access their utilities. This makes Python very light weight since the base language does not need to load all of these extra utilities unless we ask it to. To load a package that is installed on our system we can call the `import` function like below. Here we are also using a package that is not part of the standard library but was installed separately, called requests, which is used to download data from the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data files for this notebook\n",
    "Run the bash script below to create a new folder and download two files that we will use in this notebook into that folder. This code should look familiar, we used very similar bash commands in the notebooks from session 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p datafiles/\n",
    "wget http://eaton-lab.org/data/40578.fastq.gz -q -O datafiles/40578.fastq.gz\n",
    "wget http://eaton-lab.org/data/iris-data-dirty.csv -q -O datafiles/iris-data-dirty.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform the same task using Python. Here we will name the directory for the files \"datafiles2\" to differentiate it. In this case the Python version of the code looks quite a bit more complicated than the bash script. This isn't always the case, indeed Python code is often much simpler to read. By the end of this notebook you should be able to understand the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new directory\n",
    "os.makedirs(\"datafiles2\", exist_ok=True)\n",
    "\n",
    "# download files to that directory\n",
    "url1 = \"https://eaton-lab.org/data/40578.fastq.gz\"\n",
    "with open(\"./datafiles2/40578.fastq.gz\", 'wb') as ffile:\n",
    "    ffile.write(requests.get(url1).content)\n",
    "\n",
    "url2 = \"https://eaton-lab.org/data/iris-data-dirty.csv\"\n",
    "with open(\"./datafiles2/iris-data-dirty.csv\", 'wb') as ffile:\n",
    "    ffile.write(requests.get(url2).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List directories\n",
    "Another common tool that we used in the bash terminal is the `ls` command to look at the files in a given location in the filesystem. Below is the `ls` command as well as a Python equivalent. The `os.listdir()` function in Python returns the contents as a `list`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40578.fastq.gz\n",
      "helloworld.txt\n",
      "iris-data-dirty.csv\n",
      "newfiles.txt\n",
      "newfile.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls datafiles/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['40578.fastq.gz', 'iris-data-dirty.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"datafiles2/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using packages\n",
    "The `os` package has many functions but we will be using just a small part of it today, primarily the `path` submodule. Just like everything else in Python packages are also objects, and so we can access all of the functions in this package using tab completion. Put your cursor after the period in the cell below and press `<tab>` to see available options in `os`. There are many!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use tab-completion after the '.' to see available options in os\n",
    "os."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filepath operations with the `os` package\n",
    "A type of string that is often difficult to format properly when writing code is a filepath. If the string representation of a filepath is incorrect by even a single typo then the path will not be found. This becomes extra tricky when a program needs to access filepaths on different types of computers, since filepaths look different on a Mac and PC, for example. Here understanding the filesystem hierarchy that we learned in lesson 1 becomes important. Fortunately the `os.path` package makes this easy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `os.path`\n",
    "The `os.path` submodule is used to format filepaths. We can expand shortened path names, we can join together multiple paths, we can search for special directories like $HOME, or current directory. Essentially, the package is making calls similar to those we learned from bash scripting last week, such as `pwd` to show your current directory, or `~` as a shorthand for your home directory. Here we can access those filepaths as string variables and work with them very easily. \n",
    "\n",
    "NB: The goal here is not for you to master the `os` package, but to understand that many such packages exist in the Python standard library and that you can use tab-completion, google search, and other sources to find them and how to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/deren'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return my $HOME directory\n",
    "os.path.expanduser(\"~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/deren/Documents/genomics-course/2-genes/notebooks'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert relative path to a full path\n",
    "os.path.abspath('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Action:</b> Write a relative path to the iris-data-dirty.csv file that we downloaded earlier and expand it to a full path using the `os.path.abspath()` function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/deren/Documents/genomics-course/2-genes/notebooks/datafiles/iris-data-dirty.csv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath(\"./datafiles/iris-data-dirty.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations on filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/deren/Documents/genomics-course/2-genes/notebooks'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign my current dir to a variable\n",
    "curdir = os.path.abspath('.')\n",
    "curdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'notebooks'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the lowest level directory in curdir\n",
    "os.path.basename(curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/deren/Documents/genomics-course/2-genes'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the directory structure above curdir\n",
    "os.path.dirname(curdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining filepaths\n",
    "Because it can be hard to keep track of the \"/\" characters between directories and filepaths it is useful to use the `.join` function of the `os.path` module to join together path names. Here we will create string variable with a new pathname for a file that doesn't yet exist in our current directory. You can see in the three examples below that it doesn't matter when we include a \"/\" after a directory name or not, the `join` function figures it out for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/fakeuser/folder1/folder2/newfile.txt\n",
      "/home/user/fakeuser/folder1/folder2/newfile.txt\n",
      "/home/user/fakeuser/folder1/folder2/newfile.txt\n"
     ]
    }
   ],
   "source": [
    "# see how os.path.join handles '/' characters in path names\n",
    "print(os.path.join(\"/home/user/fakeuser\", \"folder1/\", \"folder2\", \"newfile.txt\"))\n",
    "print(os.path.join(\"/home/user/fakeuser\", \"folder1\", \"folder2\", \"newfile.txt\"))\n",
    "print(os.path.join(\"/home/user/fakeuser/\", \"folder1/\", \"folder2/\", \"newfile.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/deren/Documents/genomics-course/2-genes/notebooks/newfile.txt'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the full path name to a newfile in our current directory\n",
    "newfile = os.path.join(curdir, \"newfile.txt\")\n",
    "newfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing files\n",
    "\n",
    "The function `open` can be used to create views of files. The format for this is `open(filename, mode)` where mode is the thing you plan to do with this file. The main arguments for this are `w` for 'write', `r` for 'read', or `a` for 'append'. Below we will use `w` to write, which we can use to create a new file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='./datafiles/helloworld.txt' mode='w' encoding='UTF-8'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get an open file object\n",
    "ofile = open(\"./datafiles/helloworld.txt\", 'w')\n",
    "\n",
    "# return the file object\n",
    "ofile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File objects\n",
    "As with other objects, this variable `ofile` has attributes and functions that we can access and see by using tab-completion. Move your cursor to the end of the object below after the period and use tab to see some of the options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use tab to see options associated with open file objects\n",
    "ofile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `.write()` function to write a string to the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write a string to the file. \n",
    "# It returns the number of characters written, which we can ignore for now.\n",
    "ofile.write(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when we are done writing to the file use .close()\n",
    "ofile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading files\n",
    "To read data from a file we need to first open a file object, just like when we wrote to a file, but now we use the mode flag `r`. We can now access the data in the file using the `.read()` function. Below we read data form the file and store the result as a string variable called `idata`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a file object for reading\n",
    "ifile = open(\"./datafiles/iris-data-dirty.csv\", 'r')\n",
    "\n",
    "# read all contents of the file as a string\n",
    "idata = ifile.read()\n",
    "\n",
    "# close the file object\n",
    "ifile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've stored the contents of the file in the variable `idata` we can interact with it just like it is any other string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.1,3.5,1.4,0.2,Iris-setosa\\n4.9,3.0,1.4,0.2,Iris-s'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## show the first 50 characters\n",
    "idata[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gzip compressed files\n",
    "Gzip compression is easily handled in Python using the standard library. The `gzip` module has an `open()` function that acts just like the regular `open` function to create a file object. We need to use the `gzip` version instead of the regular `open` function to open and read a gzipped file properly. Let's try it out on the compressed fastq file we just downloaded. We'll also practice using `os.path` to find the full filepath of the `40578.fastq.gz` file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get full path to the file in our current directory\n",
    "gzfile = os.path.abspath(\"./datafiles/40578.fastq.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read compressed byte data from this file\n",
    "ffile = gzip.open(gzfile, 'rb')\n",
    "fdata = ffile.read().decode()\n",
    "ffile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@40578_rex.1 GRC13_0027_FC:4:1:10524:1181 length=74\n",
      "TGCAGCATAGCATAGATAATACAAGGTTNNNNNNNNNNNNNNTTTNCACAGTNTNNNATTAAACCCGGTAGNTN\n",
      "+40578_rex.1 GRC13_0027_FC:4:1:10524:1181 length=74\n",
      "IIIIIIHIIIIIIIIIGIIIH\n"
     ]
    }
   ],
   "source": [
    "# show some data from the file\n",
    "print(fdata[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and parsing data with the `read()` function\n",
    "The `read()` function is nice for reading in a large chunk of text, but it then requires us to parse that text using string processing. This is because all of the data is loaded as a big chunk of text. It then usually requires us to `split` this text using some kind of delimiter. Let's try splitting the fastq data on newline characters (`\"\\n\"`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@40578_rex.1 GRC13_0027_FC:4:1:10524:1181 length=74', 'TGCAGCATAGCATAGATAATACAAGGTTNNNNNNNNNNNNNNTTTNCACAGTNTNNNATTAAACCCGGTAGNTN', '+40578_rex.1 GRC13_0027_FC:4:1:10524:1181 length=74', 'IIIIIIHIIIIIIIIIGIIIHIIIBB:B##############################################', '@40578_rex.2 GRC13_0027_FC:4:1:13011:1181 length=74', 'TGCAGAGTCTACCCAAAGGTTCAGGCCGNNNNNNNNNNNNNNGTTNATACGTNTNNNTATTTCTATGAGAANCN', '+40578_rex.2 GRC13_0027_FC:4:1:13011:1181 length=74', 'GGGGHHHHHHHHHHHHHHHEBG<G?;??##############################################', '@40578_rex.3 GRC13_0027_FC:4:1:15237:1184 length=74', 'TGCAGAGTCCTAAATCTATTTCCTCTTCNNNNGNNNNNNNATGCATGCAACCTCCNNTCGCCACCTGTACGNAN']\n"
     ]
    }
   ],
   "source": [
    "# split fastq string data on newline characters to return a list\n",
    "fastqlines = fdata.split(\"\\n\")\n",
    "\n",
    "# print the first 10 list elements\n",
    "print(fastqlines[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The fastq file format\n",
    "Let's take a side quest now and read some details of the [fastq file format here](https://en.wikipedia.org/wiki/FASTQ_format). This is a file format for next-generation sequence data that we will use frequently throughout this course. Fastq files can be really large, often multiple gigabytes (Gb) of data. Our downloaded example file is relatively small, though. \n",
    "\n",
    "As the link above describes, the fastq format stores labeled sequence data in a sequence of four lines at a time. That is one sequenced read (a length of DNA information) is written over four lines. The first line labels the read with unique identifying information. The second line contains the sequence data. The third line is a spacer. And the fourth line contains quality scores for each base in the read. \n",
    "\n",
    "Because we split the file at every line break, we can easily look at the first four lines of data using indexing on the list object `fastqlines`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@40578_rex.1 GRC13_0027_FC:4:1:10524:1181 length=74'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first line: identifier\n",
    "fastqlines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TGCAGCATAGCATAGATAATACAAGGTTNNNNNNNNNNNNNNTTTNCACAGTNTNNNATTAAACCCGGTAGNTN'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the second line: sequence data\n",
    "fastqlines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+40578_rex.1 GRC13_0027_FC:4:1:10524:1181 length=74'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the third line: spacer/repeat\n",
    "fastqlines[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IIIIIIHIIIIIIIIIGIIIHIIIBB:B##############################################'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the fourth line: quality scores\n",
    "fastqlines[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phred quality scores\n",
    "The quality scores in the fastq sequence format are stored using an ASCII encoding, which is a way of representing a number using a single character of text. This data was generated on a modern Illumina machine, and so the scores are actually encoded by the ASCII character + 33. Python has the function `ord()` to convert string characters to ints, and `chr()` to convert ints to ASCII character strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert string to int\n",
    "ord(\"A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert int to str\n",
    "chr(65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[73, 73, 73, 73, 73, 73, 72, 73, 73, 73]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get first 10 phred scores from a line from the fastq file\n",
    "phreds = fastqlines[3][:10]\n",
    "\n",
    "## get ASCII for a string of phred scores\n",
    "[ord(i) for i in phreds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## subtract the built-in offset amount from each number \n",
    "phred33 = [ord(i) - 33 for i in phreds]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0001,\n",
       " 0.0001,\n",
       " 0.0001,\n",
       " 0.0001,\n",
       " 0.0001,\n",
       " 0.0001,\n",
       " 0.00012589254117941674,\n",
       " 0.0001,\n",
       " 0.0001,\n",
       " 0.0001]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to probabilities of being wrong\n",
    "[10 ** (-i / 10) for i in phred33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing (splitting) text on different characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at the fastq file data we can see that each four line element could also be separated by a `\"\\n@\"` character. This is because the identifier in the first line will always start with a \"@\" character. Splitting the file into string objects that represent separate reads of the file, instead of just lines, can make it easier to parse and read the file. Let's try this now by parsing the file and counting the number of reads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first read: \n",
      "@40578_rex.1 GRC13_0027_FC:4:1:10524:1181 length=74\n",
      "TGCAGCATAGCATAGATAATACAAGGTTNNNNNNNNNNNNNNTTTNCACAGTNTNNNATTAAACCCGGTAGNTN\n",
      "+40578_rex.1 GRC13_0027_FC:4:1:10524:1181 length=74\n",
      "IIIIIIHIIIIIIIIIGIIIHIIIBB:B##############################################\n",
      "\n",
      "The last read: \n",
      "40578_rex.125 GRC13_0027_FC:4:1:2571:1496 length=74\n",
      "TGCAGCTCACGGTCGTGAGGGTGAGCTTATTTTTTTGTGAACTGTCTCAACTGCTCGTGAGGGTCCTCACGATT\n",
      "+40578_rex.125 GRC13_0027_FC:4:1:2571:1496 length=74\n",
      "IIIIIGHIIIIIHIIIIFIIIDIHGIIIBGIIFIDIDIHHIDIHEIHIIIEEEIHIIE>CEEE:DDBDDFECC8\n",
      "\n",
      "\n",
      "N reads in the file = 125\n"
     ]
    }
   ],
   "source": [
    "## split the fdata string on each occurrence of \"\\n@\"\n",
    "freads = fdata.split(\"\\n@\")\n",
    "\n",
    "## print the first element in the list\n",
    "print(\"The first read: \\n{}\".format(freads[0]))\n",
    "\n",
    "## print the last element in the list\n",
    "print(\"\\nThe last read: \\n{}\".format(freads[-1]))\n",
    "\n",
    "## print the number of reads in the file\n",
    "print(\"\\nN reads in the file = {}\".format(len(freads)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using context to automatically open & close files\n",
    "\n",
    "In Python there is a special keyword called `with` that can be used to wrap statements into a context dependency. That means that everything which takes place indented within the statement will be able to access information about the outer statement. This is most often used for opening file objects. The reason being, when you open a file object using the `with` statement it is designed to automatically close the file when you end the `with` statement. In other words, this is just a shortcut to make your code a little bit shorter, by avoiding having to write a `.close()` argument for every file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "## infile will automatically close when finished.\n",
    "with open(\"./datafiles/iris-data-dirty.csv\", 'r') as infile:\n",
    "    data = infile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5.1,3.5,1.4,0.2,Iris-setosa\\n',\n",
       " '4.9,3.0,1.4,0.2,Iris-setosa\\n',\n",
       " '4.7,3.2,1.3,0.2,Iris-setosa\\n',\n",
       " '4.6,3.1,1.5,0.2,Iris-setosa\\n',\n",
       " '5.0,3.6,1.4,0.2,Iris-setosa\\n',\n",
       " '5.4,3.9,1.7,0.4,Iris-setosa\\n',\n",
       " '4.6,3.4,1.4,0.3,Iris-setosa\\n',\n",
       " '5.0,3.4,1.5,0.2,Iris-setosa\\n',\n",
       " '4.4,2.9,1.4,0.2,Iris-setosa\\n',\n",
       " '4.9,3.1,1.5,0.1,Iris-setosa\\n']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data from the web in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard format for using the `requests` library is to make a GET request to a url, which is a request to read the data from that page. This will return a `response` object which we can then access for information. The `response` object will contain an error message if the url is invalid, or blocked, and it will contain the HTML text of the webpage if it is successful. \n",
    "\n",
    "We used this method to download data at the top of this notebook. Now we'll look at it in a bit more detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store urls as strings\n",
    "url1 = \"https://eaton-lab.org/data/40578.fastq.gz\"\n",
    "url2 = \"https://eaton-lab.org/data/iris-data-dirty.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `requests.get()` function returns a new variable 'response', which is a Python object just like the other object types we've learned about. We can access functions of this object using tab completion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the response object (200 means successful GET)\n",
    "response = requests.get(url2)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.1,3.5,1.4,0.2,Iris-setosa\\n4.9,3.0,1.4,0.2,Iris-s'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first 50 characters of data\n",
    "response.text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5.1,3.5,1.4,0.2,Iris-setosa',\n",
       " '4.9,3.0,1.4,0.2,Iris-setosa',\n",
       " '4.7,3.2,1.3,0.2,Iris-setosa',\n",
       " '4.6,3.1,1.5,0.2,Iris-setosa',\n",
       " '5.0,3.6,1.4,0.2,Iris-setosa',\n",
       " '5.4,3.9,1.7,0.4,Iris-setosa',\n",
       " '4.6,3.4,1.4,0.3,Iris-setosa',\n",
       " '5.0,3.4,1.5,0.2,Iris-setosa',\n",
       " '4.4,2.9,1.4,0.2,Iris-setosa',\n",
       " '4.9,3.1,1.5,0.1,Iris-setosa']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the string of text on each newline character\n",
    "lines = response.text.split(\"\\n\")[:10]\n",
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join: combine multiple string elements into a single string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often useful to split a string into separate elements as a list, and then operate on those list elements. When finished, we then wish to join the list elements back together into a string object. This can be done using the `.join()` function, which is a function of string objects. The object calling join is the string that you want to be placed in between each element of the list being joined. Some examples below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.1,3.5,1.4,0.2,Iris-setosa4.9,3.0,1.4,0.2,Iris-setosa4.7,3.2,1.3,0.2,Iris-setosa4.6,3.1,1.5,0.2,Iris-setosa5.0,3.6,1.4,0.2,Iris-setosa5.4,3.9,1.7,0.4,Iris-setosa4.6,3.4,1.4,0.3,Iris-setosa5.0,3.4,1.5,0.2,Iris-setosa4.4,2.9,1.4,0.2,Iris-setosa4.9,3.1,1.5,0.1,Iris-setosa'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join together lines with no separator\n",
    "\"\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.1,3.5,1.4,0.2,Iris-setosa\\n4.9,3.0,1.4,0.2,Iris-setosa\\n4.7,3.2,1.3,0.2,Iris-setosa\\n4.6,3.1,1.5,0.2,Iris-setosa\\n5.0,3.6,1.4,0.2,Iris-setosa\\n5.4,3.9,1.7,0.4,Iris-setosa\\n4.6,3.4,1.4,0.3,Iris-setosa\\n5.0,3.4,1.5,0.2,Iris-setosa\\n4.4,2.9,1.4,0.2,Iris-setosa\\n4.9,3.1,1.5,0.1,Iris-setosa'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join on newline characters\n",
    "\"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1,3.5,1.4,0.2,Iris-setosa\n",
      "4.9,3.0,1.4,0.2,Iris-setosa\n",
      "4.7,3.2,1.3,0.2,Iris-setosa\n",
      "4.6,3.1,1.5,0.2,Iris-setosa\n",
      "5.0,3.6,1.4,0.2,Iris-setosa\n",
      "5.4,3.9,1.7,0.4,Iris-setosa\n",
      "4.6,3.4,1.4,0.3,Iris-setosa\n",
      "5.0,3.4,1.5,0.2,Iris-setosa\n",
      "4.4,2.9,1.4,0.2,Iris-setosa\n",
      "4.9,3.1,1.5,0.1,Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "# remember newlines are only rendered when you print\n",
    "print(\"\\n\".join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.1,3.5,1.4,0.2,Iris-setosaHelloworld4.9,3.0,1.4,0.2,Iris-setosaHelloworld4.7,3.2,1.3,0.2,Iris-setosaHelloworld4.6,3.1,1.5,0.2,Iris-setosaHelloworld5.0,3.6,1.4,0.2,Iris-setosaHelloworld5.4,3.9,1.7,0.4,Iris-setosaHelloworld4.6,3.4,1.4,0.3,Iris-setosaHelloworld5.0,3.4,1.5,0.2,Iris-setosaHelloworld4.4,2.9,1.4,0.2,Iris-setosaHelloworld4.9,3.1,1.5,0.1,Iris-setosa'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join on an arbitrary phrase\n",
    "\"Helloworld\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Action:</b> \n",
    "    This challenge builds on the last challenge from the last notebook. You can reuse your function from the last notebook to generate random sequence data. Write code below to combine a fasta header (e.g., \"> sequence name\") and random sequence data to create valid fasta data. Then write the data to a file and save it as \"datafiles/sequence.fasta\". \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# create a fasta header\n",
    "header = \"> yeast chromosome 1\"\n",
    "\n",
    "# create random sequence data\n",
    "random_dna = \"\".join(random.choice(\"ACGT\") for i in range(20))\n",
    "\n",
    "# combine with a \\n separator to create valid fasta\n",
    "fasta = header + \"\\n\" + random_dna\n",
    "\n",
    "# write to a file\n",
    "with open(\"./datafiles/sequence.fasta\", 'w') as out:\n",
    "    out.write(fasta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Action:</b> \n",
    "    You have now learned about two sequence file formats, fasta and fastq. If you do not remember the details of fasta then use google or look back at your notebooks from session 1. Fastq contains more information than fasta since it also stores quality information for each base. Your challenge here is to write a function to convert one format to the other. All of the code you need is composed in snippets in examples above. Feel free to use google or the chatroom to seek further help if needed. Your answer must: (1) Write a function; (2) The function must read the 'datafiles/40578.fastq.gz' file from disk; (3) It must convert the data to fasta format; and (4) It must write the result to a file \"datafiles/40578.fasta\".     \n",
    "    \n",
    "Be sure you look at your fasta file after you write it to check that it looks how you expect. If not, modify your code and try again. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) create a function\n",
    "def converter(fastq_file):\n",
    "    \n",
    "    # (2) read the fastq file and store data\n",
    "    with gzip.open(fastq_file, 'rb') as infile:\n",
    "        fastq_data = infile.read().decode()\n",
    "    \n",
    "    # (3) convert the file to fastq...\n",
    "    # make a list to store data\n",
    "    fasta_data = []\n",
    "    \n",
    "    # split into separate reads and iterate over list\n",
    "    for read in fastq_data.split(\"\\n@\"):\n",
    "\n",
    "        # split this read into 4 lines\n",
    "        rlines = read.split(\"\\n\")\n",
    "        \n",
    "        # convert each read to fasta\n",
    "        header = \"> \" + rlines[0]\n",
    "        sequence = rlines[1]\n",
    "        fasta = header + \"\\n\" + sequence + \"\\n\"\n",
    "        \n",
    "        # store in the new fasta list\n",
    "        fasta_data.append(fasta)\n",
    "        \n",
    "    # (4) write the result to a file (as a string)\n",
    "    with open(\"./datafiles/40578.fasta\", 'w') as out:\n",
    "        out.write(\"\".join(fasta_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function for testing\n",
    "converter(\"./datafiles/40578.fastq.gz\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> @40578_rex.1 GRC13_0027_FC:4:1:10524:1181 length=74\n",
      "TGCAGCATAGCATAGATAATACAAGGTTNNNNNNNNNNNNNNTTTNCACAGTNTNNNATTAAACCCGGTAGNTN\n",
      "> 40578_rex.2 GRC13_0027_FC:4:1:13011:1181 length=74\n",
      "TGCAGAGTCTACCCAAAGGTTCAGGCCGNNNNNNNNNNNNNNGTTNATACGTNTNNNTATTTCTATGAGAANCN\n",
      "> 40578_rex.3 GRC13_0027_FC:4:1:15237:1184 length=74\n",
      "TGCAGAGTCCTAAATCTATTTCCTCTTCNNNNGNNNNNNNATGCATGCAACCTCCNNTCGCCACCTGTACGNAN\n",
      "> 40578_rex.4 GRC13_0027_FC:4:1:4657:1192 length=74\n",
      "TGCAGGGTATAAATGTTTATTAGAAGATTAAGANNNNGCTGCACAAAAACCATATGACATTAAAAGAAACTCAC\n",
      "> 40578_rex.5 GRC13_0027_FC:4:1:6218:1191 length=74\n",
      "TGCAGTATAGGTGCTAAAATACATCATTAACAANNNNCTTTCTTATAATTATTTAATGTTTCATAGCATTTAAN\n",
      "> 40578_rex.6 GRC13_0027_FC:4:1:11872:1189 length=74\n",
      "TGCAGGCAAATTATGGCAGTTGAAATGAAGAAANNNNNNTAAAATGACTGCTAATTTTTTGTTAAAATGTAATN\n",
      "> 40578_rex.7 GRC13_0027_FC:4:1:15437:1199 length=74\n",
      "TGCAGTGTTTATTCTTTTGTTTGACACAAATTAANTCCTTTAGTTGGTGAACGACCAAACTCGACCAAACTCAA\n",
      "> 40578_rex.8 GRC13_0027_FC:4:1:17455:1193 length=74\n",
      "TGCAGAGCAAATAATTCTGCTAAATCTACTGAANNNNTTCTTGTTTGAGAAC\n"
     ]
    }
   ],
   "source": [
    "# read the output file to check if it worked\n",
    "with open(\"./datafiles/40578.fasta\", 'r') as infile:\n",
    "    # load the data\n",
    "    data = infile.read()\n",
    "    # print first 1000 characters\n",
    "    print(data[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Question:</b> \n",
    "   Describe each step of your function above verbally, in other words, explain how and why it works. Describe any parts that gave you trouble and how you found a solution. Enter your answer below using Markdown. \n",
    "   </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a function by wrapping the code with the `def` operator. Inside of the function I first loaded the gzip fastq file, then I converted it by splitting the file into separate reads on the \"\\n@\" character, and writing just the first two lines. I also appended \">\" to the identifier of the sequence. As I iterated through the reads in the fastq file I wrote each to a list. In the end, I used `.join` to turn the list back into a string, and wrote it to a file.  After testing it looks like the function works. I read in the output file and it looks like fasta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Action:</b> \n",
    "    Save your notebook and download as HTML to upload to courseworks.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
